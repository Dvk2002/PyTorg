{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерировать меньший датасет из 8-10 классов движения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"nturgb+d_skeletons/\"\n",
    "#### список отсутсвующих элементов так же будет доступен \n",
    "broken_files_path = \"NTU_RGBD_samples_with_missing_skeletons.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects = list(range(0, 28)) #количество людей выполняющих действия\n",
    "training_classes = [1,2,3,4,5,6,7,8,9,10] #классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\n",
    "training_cameras = [1, 2, 3] \n",
    "\n",
    "num_joint = 25\n",
    "max_frame = 300 # Длина отрезка которую мы вычленяем из большого датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS={0 :'drink water', 1 :'eat meal/snack', 2 :' brushing teeth', \n",
    "        3 :'brushing hair', 4 :'drop', 5 :'pickup', 6 : 'throw',\n",
    "        7 : 'sitting down', 8 : 'standing up (from sitting position)',\n",
    "        9 : 'clapping'\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path, broken_files_path):\n",
    "    labels = []\n",
    "    files = []\n",
    "    action_classes = {}\n",
    "    counter = 0\n",
    "    files_counter = {}\n",
    "              \n",
    "    with open(broken_files_path, 'r') as f:\n",
    "        broken_files = f.read().split(\"\\n\")\n",
    "\n",
    "    raw_files = os.listdir(data_path)\n",
    "    num_frames = 0\n",
    "\n",
    "    for filename in raw_files:\n",
    "        if filename not in broken_files:\n",
    "            action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\n",
    "            subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\n",
    "            camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\n",
    "            if action_class in training_classes and camera_id in training_cameras:  #and subject_id in training_subjects:\n",
    "                if action_class in action_classes:\n",
    "                    if files_counter[action_class] < 120:\n",
    "                        files.append([filename,action_classes[action_class]])\n",
    "                        files_counter[action_class] = files_counter[action_class] + 1\n",
    "                else:\n",
    "                    action_classes.update({action_class : counter})\n",
    "                    files_counter.update({action_class : 1})\n",
    "                    counter+=1\n",
    "                    files.append([filename,action_classes[action_class]])\n",
    "#                     labels.append([action_class])\n",
    "#     print(\"action classes: \", action_classes)\n",
    "#     print(\"action files: \", files_counter)\n",
    "    \n",
    "    return files, action_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция фильтр для того, что бы найти только координаты x,y,z(т.к. в датасете\n",
    "# хранится на порядок больше информации, нежели только координаты x,y,z)\n",
    "# (Остальные данные нам и не нужны, т.к. у нас нет ик-камер)\n",
    "def read_skeleton_filter(file):\n",
    "    with open(file, 'r') as f:\n",
    "        skeleton_sequence = {}\n",
    "        skeleton_sequence['numFrame'] = int(f.readline())\n",
    "        skeleton_sequence['frameInfo'] = []\n",
    "        for t in range(skeleton_sequence['numFrame']):\n",
    "            frame_info = {}\n",
    "            frame_info['numBody'] = int(f.readline())\n",
    "            frame_info['bodyInfo'] = []\n",
    "\n",
    "            for m in range(frame_info['numBody']):\n",
    "                body_info = {}\n",
    "                body_info_key = [\n",
    "                    'bodyID', 'clipedEdges', 'handLeftConfidence',\n",
    "                    'handLeftState', 'handRightConfidence', 'handRightState',\n",
    "                    'isResticted', 'leanX', 'leanY', 'trackingState'\n",
    "                ]\n",
    "                body_info = {\n",
    "                    k: float(v)\n",
    "                    for k, v in zip(body_info_key, f.readline().split())\n",
    "                }\n",
    "                body_info['numJoint'] = int(f.readline())\n",
    "                body_info['jointInfo'] = []\n",
    "                for v in range(body_info['numJoint']):\n",
    "                    joint_info_key = [\n",
    "                        'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n",
    "                        'orientationW', 'orientationX', 'orientationY',\n",
    "                        'orientationZ', 'trackingState'\n",
    "                    ]\n",
    "                    joint_info = {\n",
    "                        k: float(v)\n",
    "                        for k, v in zip(joint_info_key, f.readline().split())\n",
    "                    }\n",
    "                    body_info['jointInfo'].append(joint_info)\n",
    "                frame_info['bodyInfo'].append(body_info)\n",
    "            skeleton_sequence['frameInfo'].append(frame_info)\n",
    "\n",
    "    return skeleton_sequence\n",
    "\n",
    "# Здесь мы используем нашу функцию фильр и оформляем дату в x,y,z-cкоординаты\n",
    "def read_xyz(file, max_body=1, num_joint=25):\n",
    "    seq_info = read_skeleton_filter(file)\n",
    "    data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\n",
    "    for n, f in enumerate(seq_info['frameInfo']):\n",
    "        for m, b in enumerate(f['bodyInfo']):\n",
    "            for j, v in enumerate(b['jointInfo']):\n",
    "                if m < max_body and j < num_joint:\n",
    "                    data[m, n, j, :] = [v['x'], v['y'], v['z']]\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coords_blocks(test_file, chonk_len = 45):   \n",
    "    frame_counter = 0\n",
    "    new_labels = []\n",
    "    new_frames = []\n",
    "    blocks = []\n",
    "    \n",
    "    test_frames = read_xyz(data_path + test_file[0])[0]\n",
    "#     print(test_frames.shape)\n",
    "    label = test_file[1]\n",
    "    slice_len = chonk_len * int(len(test_frames)/chonk_len)\n",
    "\n",
    "\n",
    "    for index in range(len(test_frames[:slice_len])):\n",
    "        frame_counter += 1\n",
    "        new_frames.append(test_frames[index].flatten())\n",
    "        if frame_counter == chonk_len:\n",
    "            frame_counter = 0\n",
    "            blocks.append(np.array(new_frames))\n",
    "#             print(np.array(new_frames).shape)\n",
    "            new_labels = new_labels + [label]\n",
    "            new_frames = []\n",
    "#     print(new_labels,len(blocks))   \n",
    "            \n",
    "    return blocks, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### список файлов с лейблами на каждый файл \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Здесь выносится сгенерированный список лейблов с номером класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_(chonk_len):\n",
    "    \n",
    "    working_files_with_labels, action_classes = read_data(data_path, broken_files_path)\n",
    "    data = []\n",
    "    labels = []\n",
    "    numbers = {x: 0 for x in range(len(action_classes))}\n",
    "    for file in working_files_with_labels:\n",
    "        frames_blocks, label = create_coords_blocks(file, chonk_len)\n",
    "        if label != [] and numbers[label[0]] <= 150:\n",
    "    #         print(numbers[label[0]],len(label))\n",
    "            numbers[label[0]] = numbers[label[0]] + len(label)\n",
    "\n",
    "            data = data + frames_blocks\n",
    "            labels = labels + label\n",
    "    #         print(labels)\n",
    "    data_np = np.asarray(data)\n",
    "    labels_np = np.asarray(labels)\n",
    "\n",
    "    data_sq = data_np.reshape(len(data_np), -1)\n",
    "    test_data = pd.DataFrame(data_sq)\n",
    "    test_labels = pd.DataFrame(labels_np)\n",
    "    test_data['labels'] = test_labels\n",
    "    \n",
    "    return test_data.to_csv(\"skeletons_classes_1_30.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    # Для того, что бы инициализировать LSTM нам нужно указать:\n",
    "    # input_dim - размерность входного тензора. тензор входит в формате (seq_len, batch, input_dim)\n",
    "    # (batch_size, seq, inp_dim) - if batch_first=True\n",
    "    # hidden_dim - размерность вектора состояния h\n",
    "    # output_dim - размерность выхода\n",
    "    # layer_num - количество скрытых слоев в сети\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim,layer_num,batch_first=True)\n",
    "        \n",
    "        self.dr = torch.nn.Dropout2d(0.1)\n",
    "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        lstm_out,(hn,cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skeleton_Dataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None,chonk_len=45):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.transform = transform(chonk_len)\n",
    "        self.labels = self.data.iloc[:,-1]\n",
    "        self.chonk_len=chonk_len\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = np.asarray(self.data.iloc[idx,:-1]).reshape(45,25*3)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform != None:\n",
    "            item = transform(item)\n",
    "            \n",
    "        \n",
    "\n",
    "        return (item, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Skeleton_Dataset(file_path = \"skels.csv\", transform=transform_,chonk_len=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.75*len(dataset)),int(0.25*len(dataset))])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(file_path = \"skels.csv\", transform=transform_,chonk_len=45) :\n",
    "    dataset = Skeleton_Dataset(file_path = \"skels.csv\", transform=transform_,chonk_len=45)\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.75*len(dataset)),int(0.25*len(dataset))])\n",
    "    train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = 1, shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "#     print(output.topk(5))\n",
    "    return LABELS[category_i], category_i\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_hidden = 128,n_joints = 25*3, \n",
    "                n_categories = len(LABELS),\n",
    "               n_layer = 2, epochs=300, seed=101,\n",
    "               learning_rate = 0.009):\n",
    "\n",
    "\n",
    "    rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
    "    rnn.to(device)\n",
    "\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, learning_rate, epochs=epochs, \n",
    "                                                    steps_per_epoch=len(train_loader))\n",
    "\n",
    "    all_losses = []\n",
    "    start = time.time()\n",
    "    counter = 0\n",
    "\n",
    "    # torch.save(rnn.state_dict(), \"model.pth\")\n",
    "    # rnn.load_state_dict(torch.load(\"model.pth\"))\n",
    "    # optimizer.param_groups[0]['lr'] = 0.009\n",
    "\n",
    "    for epoch in range(epochs):  \n",
    "        current_loss = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "    #     if epoch == 600:\n",
    "    #                 optimizer.param_groups[0]['lr'] = 0.005\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            output = rnn(inputs.float())\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "            current_loss += loss.item()\n",
    "            category = LABELS[int(labels[0])]\n",
    "\n",
    "            \n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eval(rnn, param=''):\n",
    "\n",
    "    total = 0\n",
    "    right = 0\n",
    "    counter = 0\n",
    "\n",
    "    rnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            counter = counter + 1\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)  \n",
    "            output = rnn(inputs.float())\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            category = LABELS[int(labels[0])]\n",
    "\n",
    "            if guess == category:\n",
    "                right = right + 1\n",
    "\n",
    "\n",
    "    print('param= ', param, 'Accuracy of the network:  ',  (100 * right / counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить уже существующую модель (предварительно проанализировав какие параметры модели нужно изменить)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader= make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param=  100 Accuracy of the network:   81.13207547169812\n",
      "param=  300 Accuracy of the network:   86.79245283018868\n",
      "param=  600 Accuracy of the network:   89.30817610062893\n",
      "param=  1000 Accuracy of the network:   87.42138364779875\n"
     ]
    }
   ],
   "source": [
    "epochs=[100,300,600,1000]\n",
    "\n",
    "for i in epochs:\n",
    "          \n",
    "    rnn=train_model(epochs=i)\n",
    "    make_eval(rnn, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param=  0.013 Accuracy of the network:   84.90566037735849\n",
      "param=  0.009 Accuracy of the network:   88.0503144654088\n",
      "param=  0.005 Accuracy of the network:   86.79245283018868\n",
      "param=  0.001 Accuracy of the network:   83.01886792452831\n"
     ]
    }
   ],
   "source": [
    "learning_rate=[0.013,0.009,0.005,0.001]\n",
    "\n",
    "for i in learning_rate:\n",
    "           \n",
    "    rnn=train_model(epochs=600, learning_rate=i)\n",
    "    make_eval(rnn, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param=  2 Accuracy of the network:   90.56603773584905\n",
      "param=  3 Accuracy of the network:   84.27672955974843\n",
      "param=  4 Accuracy of the network:   82.38993710691824\n"
     ]
    }
   ],
   "source": [
    "n_layer=[2, 3, 4]\n",
    "\n",
    "for i in n_layer:\n",
    "       \n",
    "    rnn=train_model(n_layer=i)\n",
    "    make_eval(rnn, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param=   Accuracy of the network:   91.19496855345912\n"
     ]
    }
   ],
   "source": [
    "rnn=train_model(learning_rate=0.009,epochs=600)\n",
    "make_eval(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение n_hidden не оказывет существенного влияния на модель.\n",
    "Оптимайзеры sgd и adam дают схожие результаты, rmsprop показывает хуже результат.\n",
    "Значительное влияние на итоговой результат оказывает неопределенность модели и \n",
    "cuda.manual_seed не сильно меняет ситуацию. Разница в результатах при повторных запусках\n",
    "может достигать 5-10%,  сохранение и загрузка параметров инициалированной модели также\n",
    "не избавляет от плавающей метрики.\n",
    "Выход при оценки модели видится в создании ансамблей из повторных запусков модели, но это требует много времени.\n",
    "Можно попробывать инициализировать веса каждого слоя, но я с этим не разбирался еще."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменить модель: посмотреть зависимость от количества LSTM модулей в нашей модели  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Увеличение количества слоев LSTM ухудшает качество медели. Воспроизводить не буду, потому что долго тренеруется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерировать другой датасет с меньшим количеством “кадров” в серии и сравнить улучшилось или ухудшилось качество предсказания. Провести несколько таких итераций, дать свою оценку уменьшению и увеличению кадров, назвать оптимальное, на ваш взгляд, их количество. Желательно сделать так, чтобы длина последовательности передавалась как атрибут класса.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param=  15 Accuracy of the network:   88.67924528301887\n",
      "param=  25 Accuracy of the network:   84.90566037735849\n",
      "param=  45 Accuracy of the network:   89.937106918239\n",
      "param=  65 Accuracy of the network:   86.79245283018868\n",
      "param=  85 Accuracy of the network:   86.79245283018868\n"
     ]
    }
   ],
   "source": [
    "chonk_lens=[15,25,45,65,85]\n",
    "\n",
    "for i in chonk_lens:\n",
    "    \n",
    "     \n",
    "    train_loader, test_loader= make_data(chonk_len=i)\n",
    "    rnn=train_model()\n",
    "    make_eval(rnn, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
